## Lesson Introduction
---
Before actively launching any attacks, the PenTest team must complete a footprinting exercise. The goal of this activity is to gather as much information about the target as possible, that includes building a profile on the organization, network, and systems. In this lesson, we’ll see how to collect essential data, such as passwords and content within websites that can expose weaknesses. During this process, the team will find a great deal of information publicly available, which can be overwhelming. To aid in this discovery, the PenTest team can use powerful ***Open-Source Intelligence Tools (OSINT)*** such as ***Shodan***, ***Maltego***, and ***Recon-ng*** that can help ferret out information.

## Lesson Objectives
---
In this lesson, you will:

- Produce information on the target, such as contacts, network, and system information by using online resources.
- Gather essential data, such as passwords, comments within HTML code, and file metadata.
- Compile website information that includes cryptographic flaws and links that can lead the team to hidden information.
- Explore open-source intelligence tools that aid in identifying vulnerabilities, such as network devices using default passwords.

## Topic 3A - Discover the Target
---
> [!note] Exam Objectives Covered
> *2.1 Given a scenario, perform passive reconnaissance.*
> *5.3 Explain use cases of the following tools during the phases of a penetration test.*

Once the team has defined the project boundaries and outlined the rules of engagement, the next step is to discover as much as possible about the target. The team will conduct passive reconnaissance by scouring online resources such as social media and job boards to identify key technical and administrative contacts within the organization. Concurrently, the team will utilize utilities such as Nslookup and dig ***Domain Name System (DNS)*** name resolution to learn more about the structure of an organization's network.

Let’s begin by learning the importance of this critical phase in the PenTesting process.

### Gathering Information
---
Footprinting and reconnaissance involves identifying, discovering, and obtaining information, and involves a wide variety of tasks, goals, and outcomes that are essential to the success of the engagement. When complete, the findings will help the team to better assess the target and evaluate possible attack vectors.

During this phase, the team will search for key contacts, information, and technical data that can provide a better understanding of the business operations and reputation of the target organization. To accomplish this, the team will comb through online articles, news items, social media, and press releases. The information will help the team test the security posture of an organization, which is an overall assessment on how well the organization can prevent and/or respond to a cyberattack.

While gathering intel, the team should record their findings and conclusions in a way that everyone can view and modify. One possibility is to create a spreadsheet that lists all major findings. Each finding is listed on their own row, followed by ideas for the next step(s) in the corresponding columns, as shown below:
![[6008-1622927494064-03_Spreadsheet.png]]
*A spreadsheet that details findings (Screenshot courtesy of Microsoft.)*

This is so you can refer to the document when you need to recall the details of the activity along with suggestions you had for acting on that information.

In this section, we’ll discover how resources can help give the team a clear picture of the target and provide choices in the methods used to launch an attack. First, let’s look at how the team can glean a complete picture of an organization using the Internet.

#### Providing Insight on the Target
Online resources can reveal a great deal about how a business is operating or changing, along with how this will affect day-to-day operations. For example, an organization might issue a press release detailing the acquisition of another company and describe what this means for the parent company's people, products, and technology.

Resources can include job listings, metadata, and website information. For example, on the “about us” page of a company website, you can find details on the leadership of an organization, as shown in the screenshot below:
![[Pasted image 20240104110138.png]]
*The "about us" page for CompTIA (Screenshot courtesy of CompTIA.)*

In addition, news outlets can also report on an organization's impropriety or other negative traits that surround its business. The information found won't always reveal something significant on its own. However, used in conjunction with other **Open-Source Intelligence (OSINT)** tools, this can help the team construct an accurate account of the target organization.

Many assets found online are rich with information. If the team finds one source, they will most likely find others that will help paint a picture of the organization, discover technical contacts, and unearth disgruntled employees. For example, while searching for information on 515support.com, the team might unearth a blog and other resources from some employees that can expose negative issues that can include:

- The company doesn’t have a work/life balance.
- Managers are incompetent.
- The company lacks proper training programs.
- Coworkers are fired for trivial reasons.

This type of information might be anecdotal; however, collectively it can help launch a social engineering attack that targets disgruntled employees.

The data obtained by the team can either help frame the attacks in certain ways or direct the team to reconsider the overall attack strategy. This is especially true when preparing unknown, partially unknown tests, as it provides the team with potentially actionable data on the target.

Attempting to launch an attack on the target without properly gathering critical intel will make it harder to achieve the goals of the PenTest and may possibly result in failure.

During this exercise, the team will need to keep in mind that not all information is useful. It's difficult to predict what type of information will be relevant until you learn more about your target, which is what the process of information gathering is supposed to achieve. As a result, the team will need to gather and then analyze the data to identify what is and is not relevant to the PenTest operation.

#### Leveraging the Intel
Once the team begins to drill down on online resources, they will soon recognize how the intel can provide information on the following:

- The role the employees play in the organization, their job titles, management levels along with day-to-day responsibilities.
- The teams, their colleagues, and the departments where they work.
- Business related details such as phone numbers, email addresses, office and workspace locations.
- The overall organizational technical aptitude and whether they've been properly trained in end-user security.
- The people's mindsets, politics, and perspectives on their employers and colleagues.

How you leverage the information about people you gathered from various resources, such as whois, social media, the organization's website, and more, will depend on several factors.

Consider the following scenarios:

- The team gathers an executive's email address, office location, role in the company and who they manage, all from the organization's website. The team then uses the information to prepare a spear phishing attack to try and get the company to authorize a fraudulent payment.
- Your team discovers the social media profiles of an accounts payable employee that has information on their date of birth, relationships, interests, and more. You then use these details in a wordlist to prepare a password cracking attempt with a more targeted approach.
- Your team discovers that a network administrator is dissatisfied with their colleagues by reading the employee's rambling posts on Facebook. The employee complains that their colleagues have a lax attitude toward securing and monitoring the network. You then focus your tests on finding the weaknesses that may exist due to these negligent employees.

Keep in mind, not all contacts who may be useful to the PenTest are necessarily employees or work with the target organization in any capacity. They can also include friends, family, or customers that have different interactions with an organization. Collectively, the information can assess a company’s overall security posture and determine the best for your team to launch a successful attack.

Next, let’s see some of the places you can locate contact information.

> [!warning] Another source of information mentioned in the PenTest+ objectives but not touched on in the content is Netblocks (https://www.netblocks.org) that show internet connectivity information. 


### Identifying Organizational Contacts
---
Depending on the target, the team will need to evaluate various websites and data repositories that can provide information on the company. Activities include pouring through social media, job listings, and websites, along with utilizing DNS resources such as whois and dig to ferret out useful information.

One way that the team can gather a great deal of data on how the target does business is by studying what’s listed on social media sites. Let’s evaluate what’s involved in this resource, next.

#### Scraping Social Media
Today, most companies that provide products and services to the public will have a profile on social media. The profiles are primarily used as a marketing channel to reach certain audiences that may not be exposed to traditional marketing. In fact, many potential customers may never even see the organization's primary website, so an organization may put extra effort into their social media presence.

Beyond the organization's profile, social media is also a rich resource for extracting data about individuals. Everyone from the executive-level managers (C-suite) to rank-and-file employees can appear on several social media sites. These individual profiles are often linked from the company's main profile, making it easier to perform reconnaissance on an organization's personnel structure. Likewise, an individual may have more than one profile in order to separate their professional life from their personal life. In either case, individual profiles may reveal much about an employee's interests, habits, behavior, relationships, and other Personally Identifiable Information (PII) . Examples of common social media sites that may provide actionable intelligence include:

- **X, formerly called Twitter,** is used to promote products and services in short statements called tweets, as well as to provide casual customer service and bolster brand loyalty and recognition.
- **Facebook** is used for more in-depth marketing and may be more likely to include images, videos, and event scheduling.
- **LinkedIn** is used primarily for networking opportunities and job searching.
- **YouTube** is used to publish videos that market an organization's products, services, and/or brand.
- **Instagram** is used to publish images that market an organization's products, services, and/or brand.
- **Reddit** is often used to target marketing efforts toward specific communities.

In addition to social media, job listings can reveal information about the organization's personnel structure, technical environments, networking architecture, and other computing infrastructure.

#### Scouring Job Listings
Organizations looking to hire will often post on public job boards. This is because the employer needs to both entice prospective employees and give the candidate enough information to determine whether they should apply. Common public job boards include the following:

- CareerBuilder
- Monster
- ZipRecruiter
- Indeed
- Glassdoor
- LinkedIn

The amount and type of information on job postings will depend on the organization's industry and the job requirements. For example, a position for a network administrator will include more information about the technical side of the organization’s operations than a sales associate position at the same company. When searching job postings, you can learn about an organization’s technology stack along with other details, such as:

- The personnel makeup of specific departments and teams, including administrator contacts.
- The lack of qualified personnel in crucial positions.
- The level of technical sophistication within the organization.
- The software architecture and services, such as web server and cloud technologies.
- The language(s) used to program in-house software.
- The types and quantities of hardware in use.
- The network and security systems that the organization employs.
- The job responsibilities.
- The certification requirements.

Social media and job listings will provide a great deal of information on the organization In addition another source of information on the technical aspects of an organization is in the DNS details, as we’ll see next.

### Examining DNS Information
---
A standard DNS query will use DNS servers to identify the ***Internet Protocol (IP)*** address behind a particular domain or resource name. The IP address might be useful as an entry point into the network, or possibly as a vector for performing more reconnaissance. However, an advanced DNS query can retrieve more information than just an IP address. For example, you can also identify individual DNS records for a particular domain, such as the following:

- **Mail Exchange (MX)** record provides the mail server that accepts email messages for a particular domain.
- **Nameserver (NS)** record lists the authoritative DNS server for a particular domain.
- **Text (TXT)** record provides information about a resource such as a server or network in human readable form.
- **Service (SRV)** record provides host and port information on services such as ***Voice over IP (VoIP)*** and ***Instant Messaging (IM)***.

DNS records are useful as they can reveal additional targets that you may not have discovered using other OSINT methods. Using certain DNS records can help the team learn more about the structure of an organization's network. For example, you may be able to identify that the organization is using specific services, like VoIP, by enumerating an SRV record.

While searching for information, there are tools that can help you perform DNS queries that include:

**Nslookup** is a command-line tool used in either a Windows or Linux operating system (OS) that can be used to query a domain and specify various record types.

**Dig** is a utility widely used on a Linux OS that can perform reverse lookups to match an IP address to a domain name.

#### Viewing DNS Records
![[Pasted image 20240104110336.png]]
*Enumerating DNS records for comptia.org (Screenshot courtesy of CompTIA)*

In addition to mail servers, service records, and nameserver information, DNS can help us discover additional information on an organization, such as key contacts within the organization. One such method is by using whois.

#### Querying Data Using whois
When an entity registers a domain name, the registrant will need to provide information, such as organizational and key contact details. The information is then stored in the whois database. While PenTesting, the team can use the whois protocol, which provides the ability to search for data related to entities that register public domains and other Internet resources.

A typical whois query can be used on a public domain like **comptia.org** in order to reveal information about that domain, such as:

- The name of the domain's registrant.
- The name and mailing address of the registrant organization.
- The email address and phone number of the registrant.
- Any previous information regarding administrative and technical contacts.
- Identifying information about the domain's registrar.
- The status of the domain, including client and server codes that concern renewal, deletion, transfer, and related information.
- The name servers the domain uses.

As shown in the graphic, a whois query can provide registrant details for a specific organization:
![[Pasted image 20240104110409.png]]
*The results of a Whois query on comptia.org. (Screenshot courtesy of CompTIA)*

A whois query can provide a lot about the target organization and how its domain is configured. The team can then use this information to take more targeted actions against the domain's contacts, as well as the underlying architecture of the domain.

|  **Tool**  | **Functionality**                                                                                                                                                                                                                                          |
| :--------: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| *nslookup* | Queries DNS to obtain domain name or IP address<br>mapping or other DNS records.                                                                                                                                                                           |
|   *dig*    | Performs DNS lookups and displays results from <br>name servers(s). Provides detailed query <br>information including time taken, message size, etc.                                                                                                       |
|  *whois*   | Queries databases that store registered users or <br>assignees such as domain names, IP address blocks,<br>or an autonomous systems. Provides information<br>on domain registration, registrar information, <br>and administrative and technical contacts. |
|   *host*   | Performs DNS lookups through converting domain <br>names to IP addresses and vice versa.                                                                                                                                                                   |

A whois query can be executed using a ***command-line interface (CLI)***, however, there are also web apps available that enable users to run queries.

As you might expect, attackers, especially spammers, use Whois data to target their operations. As a result, whois data raises issues of privacy, as queried data can reveal ***Personally Identifiable Information (PII)***, not to mention information about the organization that an attacker can leverage.

The rise of data privacy regulations like the ***General Data Protection Regulation (GDPR)*** has led to increased scrutiny of the Whois protocol. The ***Internet Corporation for Assigned Names and Numbers (ICANN)*** has stated that they aim to "reinvent" Whois to be more in line with recent privacy concerns. This may mean that data that was once publicly available through Whois will no longer be available. However, the exact details of the proposed changes are not known at this time.

> [!warning] Some registrars offer services where they set themselves as the owner and contacts, enabling the real registrant's information to remain private. This can make it more difficult for you to glean useful information from Whois.

Gathering organizational data will give the team a better picture of the organization. Once analyzed this will help determine the security posture of the organization so the team can properly frame the PenTesting activity.

## Topic 3B - Gather Essential Data
---
> [!note] Exam Objectives Covered
> *2.1 Given a scenario, perform passive reconnaissance.*
> *5.3 Explain use cases of the following tools during the phases of a penetration test.*

Data is everywhere. The key during a PenTest exercise is being able to locate essential data that can be used during the attack phase. In this section, we’ll see how we can use public source-code repositories and conduct strategic search engine analysis and enumeration. In addition, we’ll see the value of digging through archived websites and searching for images using TinEye. Let’s start with seeing how we can use source code repositories.

### Using Public Source-Code Repositories
---
Today’s fast-paced always-on world demands that developers are agile and able to quickly turn around code and update existing software. As a result, many are utilizing public source-code repositories, which promotes code sharing and collaboration. This then speeds up development times.

Today, there are dozens of source code repository hosts available to developers. Some examples include:

| **Repository** | **Features** |
| :--: | ---- |
| *GitHub* | Enables teams to work together, regardless of their location, is free to basic users, and reasonable costs for teams and enterprise users. |
| *Bitbucket* | Allows inline comments, a secured workflow, and free to small teams, fee based for larger groups. |
| *CloudForge* | Offers bug and issue tracking, discussion forums, and document management. You can get a free trial for 30 days, after which there is a nominal fee. |
| *SourceForge* | Is free to everyone, and features discussion forums and issue tracking. |
For each repository, developers generally follow a process. Let’s step through an example of how 515support.com might use a code repository:

1. 515support.com has a public repository that houses the code for several applications.
2. Each developer works on their part of source code, and only commit changes to the public repository when they are satisfied with the version.
3. The maintainer (or project leader) evaluates the code, and then will add only approved parts of the code to become part of the main source code.

Along with the convenience of the repositories, comes risks. However, developers aren’t always aware of these risks, and malicious actors examine the repositories in hopes of unearthing sensitive and restricted information. That is why viewing a company’s open-source code repository is essential during a PenTest. Some of the security vulnerabilities the team might find includes:

- Developers that post have put private files into their repositories that are then copied into the public storage area. The files can then be searched.
- Code can include information such as hostnames, IP addresses, database servers, and service configurations, which can be used to craft an attack.
- Code can include the names and information on employees, which can be used in a spear phishing attack or credential theft.
- Code can be modified, which can lead to an infrastructure attack or shut down systems or applications.
- Developers post screenshots or comments that can contain useful intelligence.
- Developers add specific information in their code, such as usernames and passwords, as shown in the following code block:

```json
tls_config
insecure_skip_verify: true
basic_auth:
username: bluedog
password: orangetigerkittens
scheme: https
tls_config:
```
Exposed code and other vulnerabilities exist. One way to locate the vulnerabilities is by actively searching using advanced searching techniques, as discussed next.

### Optimizing Search Results
---
The Internet is a vast resource for all types of information. When properly queried, search engines can produce a great deal of research on the target that can be used to frame an attack.

One method used by PenTest teams to optimize search results, is called Google hacking. The process uses the Google search engine to identify potential security weaknesses in publicly available sources, such as an organization's website.

Google hacking queries almost always include a special search operator in order to cut down on irrelevant results and focus on specific types of desired information. The following table lists some common search operators that are often used in Google hacking:

| **Operator** | **Searches** | **Example** |
| :--: | ---- | ---- |
| site | A specific site. | `site:comptia.org report` to search CompTIA's website only for results including the text "report." |
| link | Pages that link to the specified page. | `link:comptia.org report` to search for any pages that link to CompTIA's website and have the text "report" anywhere on the page. |
| filetype | Specific file types. | `filetype:pdf report` to search for PDFs including the text "report." |
| inurl | Uniform resource locator (URL) | `inurl:Certification report` to search for any pages whose URLs include the text "Certification" and have the text "report" anywhere on the page. |

Full list available here: [[Google Dorking (Hacking) Cheatsheet]]

The true power of Google hacking is in combining multiple operations into a single query. For example, following query will search CompTIA's website for any PDFs or DOCX files:

`site:comptia.org filetype:pdf OR filetype:docx inanchor:Certification report`

This will search CompTIA's website for any PDFs or DOCX files whose page titles include the word "Certification" and whose contents (title or body) include the word "report."

While the term implies that this type of advanced searching is only available using Google, other search engines have much of the same functionality. When used, this will enable the team to obtain the exact type of information you need.

Sometimes the information you need isn’t on a recent web page, but a version that was published in the past. To locate this information, the team will need to view archived pages. Let’s take a look at how this works next.

### Unearthing Archived Websites
---
When viewing a webpage on the Internet, we are viewing a slice in time. Webpages are updated, moved, or deleted, and the information you may have found last month or last year is no longer available.

For example, some sites may have listed a company directory, however because of security reasons, they removed the directory. The good news is that it may be possible to re-access this information, by using a web cache viewer.

A web cache viewer allows you to search for older versions of websites which is a snapshot of the raw HTML and some of the page contents. While most of the text is generally present, the images are not always archived. However, most of the time this will be enough to scrape data and research older activity.

Using archived websites during PenTesting can trace back to old press releases, directories, and even information on the source code that contains comments or sensitive information.

To obtain older website information, you can use a couple of different methods:

1. Use a standard cache search on a site, and you will see a recent view of the website. To do a quick check simply type `cache:<website>` in the address bar . For example,` cache:https://comptia.org`
2. Do an archived search using the Wayback Machine, which is a site that grabs and archives older websites.
3. Use a web cache viewer extension, that allows you to quickly customize your search, visit recently viewed pages, or revert back to an older page, to see what information you can discover.

Which tool you use will depend on what information you need.

Keep in mind that when searching for older websites for specific content, you may not always be successful. However, it might also unearth other useful information, such as a company directory.

In addition to searching for standard content such as spreadsheets and documents, the team might also find images that will help build a profile of the target. In the next section, let’s explore the value of searching for images.

### Searching for Images
---
In addition to other essential data required to launch an effective attack, the team can also try an image search. Searching images during the reconnaissance phase is another avenue the team can use when scouting the target to see if there is any actionable intel.

Some of the sites that offer reverse image search are as follows:

- TinEye
- Google
- Yandex
- Bing

All search engines work in a similar manner: either enter a URL or upload an image, and the search engine will then hunt for all similar images and then present the results. When searching for images, the results are not always as expected, and you may have to try more than one search engine to glean useful information.

Using an image search can help with reconnaissance or general research on a target, along with assessing the status of a company. For example, there might be a compromised image of the target or organization that doesn’t reflect the best reputation. If found, the next step is to modify or mitigate the effects of the negative reputation.

If the team is not successful in obtaining useful information on the target using an image search, another option is to use Google Alerts.

Once on the Google Alerts site, enter either a name or email address as shown:
![[Pasted image 20240104111604.png]]
You can also modify the search options, such as when to check, what language, and where to deliver the results when found. Google alerts will then monitor the web for interesting new content, and if found, Google will notify you.

## Topic 3C - Compile Website Information
---
> [!note] Exam Objectives Covered
> *2.1 Given a scenario, perform passive reconnaissance.*
> *2.2 Given a scenario, perform active reconnaissance.*
> *2.3 Given a scenario, analyze the results of a reconnaissance exercise.*
> *5.3 Explain use cases of the following tools during the phases of a penetration test.*

The internet is comprised of nearly two billion websites, many of which have one or more vulnerabilities, which can lead to an attack. That is why evaluating a target’s website during PenTesting is so important.

When preparing for a web application PenTest, the team will use the standard approach: scoping, footprinting, and planning before launching any attacks. In addition, the team will have reviewed some of the guidelines of standard testing methodologies such as the ***Open Web Application Security Project (OWASP)*** and ***Payment Card Industry Data Security Standard (PCI DSS)***.

In this section, we’ll take a look at the importance of gathering information on a target’s self-hosted or cloud-based website, in preparation for an attack. You’ll understand how to assess the site for vulnerabilities, by crawling and scraping websites for useful intel. In addition, we’ll outline the importance of evaluating a site for flaws within the ***Secure Sockets Layer (SSL)*** and ***Transport Layer Security (TLS)*** that can lead to compromise.

Let’s start with discovering the details of the target’s website.

### Enumerating the Target's Website
---
Website enumeration is done during the footprinting and reconnaissance stage to discover potential attack vectors and vulnerabilities on a web server. The team will need to determine how the target hosts the site, which can be either self-hosted, or cloud-based. How you go about testing will be outlined in the project scope. If the site is cloud-based, for example, ***Amazon Web Services (AWS)***, the team will need to adhere to the PenTesting guidelines dictated by the hosting company.

> [!warning] According to OWASP, enumeration is also referred to as Predictable Resource Location, File Enumeration, or Directory Enumeration.

Website enumeration involves discovering resources that are in use as well as the underlying technology used to host the server. Today, websites use a variety of methods to create a site, which can include hand-coded, content management system-based or template-based. The information obtained will help the team choose more effective vectors to use in an attack as well as methods to exploit vulnerabilities in specific versions of web server software.

Typically, the team will look for vulnerabilities so they can use the following attacks: ***Cross Site Scripting (XSS)***, ***SQL Injection (SQLi)***, and caching server attacks. However, if the site is an ecommerce site, the team will need to test other elements within the site. Elements include coupon and reward redemption, content management system, and integration with the payment gateway.

To begin the process, the team can use one of several tools and techniques to crawl and scrape websites.

#### Investigating the Website
There are numerous tools and techniques available to evaluate a website. Tools include browsers, Nmap, Metasploit, and DirBuster. The team can also use *forced browsing*, which is used to identify unlinked URLs or IPs from a website to gain access to unprotected resources. Forced browsing can be automated but is often a manual process due to the variance in naming conventions of application index directories and pages.

In addition, OSINT tools such as Maltego, along with standard or Google hacking searches, can reveal the technologies that a public website or other resource is using. By identifying the type of technology as well as its version information, you can better prepare to exploit specific scenarios.

For example, one way to start website enumeration is to use an HTTP header sniffing tool and enter the target's URL. The information can tell you what web server software is in use and also the response code. For example, you might get the following response:

```
<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">
<html><head>
<title>301 Moved Permanently</title>
</head><body>
<h1>Moved Permanently</h1>
<p>The document has moved <a href="https://www.comptia.org/">here</a>.</p>
<hr>
<address>Apache/2.4.29 (Ubuntu) Server at comptia.org Port 80</address>
</body></html>
```

#### Extending Your Reach
An organization's primary website for public consumption is not the only website that might help you gather background information about the organization. In addition to testing the main site, the team may be tasked to examine the target's partners, consultants, and contractors’ sites.

By extending this reach, you'll potentially expand your knowledge of the target's business operations, personnel, and assets that may reveal serious vulnerabilities within the supply chain.

The following are other potential sites that might reveal actionable information:
- Secondary sites, such as those meant for use by employees or specific customers in a business-to-business sales scenario.
- Subdomains of primary sites that aren't directly linked or easily visible from the primary site, such as administrative portals.
- Websites owned and/or operated by partner organizations, like a supplier with whom a retail vendor often works.
- Websites of the target organization's subsidiaries; or, conversely, the target's parent organization.
- Social media profiles that are used as another (or perhaps, primary) marketing outlet for the organization.

While a related website might not provide you with the same level of OSINT as the primary site, it may still provide you with extra details that you wouldn't otherwise have obtained. A partner site might reveal more about the relationship with the target organization. This could possibly provide enough intel for you to attempt to use the partner as a vector, assuming this is within the project scope. For example, the Target breach of 2014 was made possible because the attacker(s) stole network credentials from the retailer's third-party HVAC provider.

Next let’s take a look at the significance of the robots.txt file.

#### Evaluating the robots.txt File
On a public webpage, there is a chance that web crawlers will search the source code to learn about the structure of the page, and possibly find interesting information. One way to control where they search is by using a file, called robots.txt, that directs the bots to the extensible markup language (XML) sitemap file. The robots.txt file is a simple yet essential file that tells the bots where to search, and more importantly, where NOT to search.

> [!warning] Web crawlers can also be called bots, spider, spiderbot, or user agent.

The file, which is case-sensitive, can be found in a website’s top-level directory. To display the file, type robots.txt at after the end of the domain name, as shown:
```
https://<domain name>/robots.txt
```

If the site has a robots.txt file, it will be displayed. The team will then be able to examine the structure. When evaluating the file, it’s important to ensure that it has proper encoding to restrict access when searching, because if not written properly, the robots.txt can be a security risk.

The team should make sure that areas you DON’T want the bots to follow are clearly identified. For example, in the following we see that the directive is to deny access to the cart page to all user-agents.
```
Disallow: * /cart
```
However, this line will allow all bots to access all content:
```
User-agent: * Disallow:
```
Keep in mind that some bots, such as email address scrapers, may bypass the robots.txt file.

While evaluating the site for vulnerabilities, automated tools can provide a great deal of information. However, in addition to using automated tools, the team should also _manually_ inspect the site contents and links for malicious code, redirects and questionable behavior.

In addition to enumerating the website platform for vulnerabilities, the team should also take a look at the certificates within the organization’s websites as part of an information-gathering effort.

### Recognizing Certificate Flaws
---
When securely exchanging data, a website using SSL/TLS will rely on the use of digital certificates to validate the identity of the web server and exchange cryptographic keys.

> [!warning] Remember that even though you'll often see certificates referred to as SSL certificates, they're actually using TLS.

Vulnerability scanners can gather and validate certificate information to see if there are any issues. Knowing what certificates are in use, and if they are expired or otherwise problematic, can be useful to a penetration tester. Discovering out-of-date certificates often point to other administrative or support issues that can be exploited.

Let’s see how we can learn more details about a certificate.

#### Discovering Certificate Details
Digital certificates used in SSL/TLS communications are another public resource that can aid in the PenTest process. One of the more useful fields in a digital certificate from a reconnaissance perspective is the *subject alternative name (SAN)*. SANs can identify specific subdomains that can be covered by the certificate. Organizations use SANs so that they don't have to purchase and use different certificates for each individual resource. If found, any SANs listed can then be evaluated by the team.

However, some certificates simply use a wildcard (`*`) character to denote that all subdomains of the parent domain are covered by the certificate. In this case, you might not be able to identify any specific resources. For example, using an online SSL checker for CompTIA.org, will present the following results:

**Common name:** `*.comptia.org`
**SANs:** `*.comptia.org, comptia.org`
**Organization:** THE COMPUTING TECHNOLOGY INDUSTRY ASSOCIATION, INC **Org. Unit:** IS
**Location:** Downers Grove, Illinois, US
**Valid** from January 7, 2020 to February 16, 2022
**Serial Number:** 0468fa119b7cbd956a91acbe6ea05b99
**Signature Algorithm:** sha256WithRSAEncryption
**Issuer:** DigiCert SHA2 Secure Server CA

In addition to SANs, the team should investigate the Certificate Transparency (CT) framework, which are logs of public certificate authorities (CAs) that are published for anyone to access.

These logs contain information about the certificates for domains and subdomains issued by a CA. This can enable you to discover subdomains that may be no longer covered by the certificate but still exist. For example, an organization might have used a specific SAN in the past but later moved to a wildcard. That past domain might be listed in the CT logs for the issuing CA.

When conducting a search, you will see the results as follows:

![[Pasted image 20240104112954.png]]
*A partial listing of the CT logs for comptia.org (Screenshot courtesy of CompTIA.)*

In some cases, the certificate might be invalid for some reason and will be revoked. Let’s investigate how this can happen.

#### Revoking the Certificate
The certificate from the CA is a foundational element of trust among parties during an online data transaction. All web browsers have a list of certifying authorities’ and information on whether a certificate is valid or has been either invalidated or revoked.

Certificates can be revoked for a number of different reasons, such as the issuing company is no longer in business, the certificate has expired, or if the CA’s private key was somehow compromised.

If the certificate is found to be untrusted, you will most likely get an error on your browser. For example, I purposely changed the date on my computer to March 2, 2039, and then went to Google. The browser then presented this error:
![[Pasted image 20240104113030.png]]
*Warning from Google (Screenshot courtesy of Google.)*

Each certificate contains a serial number, which provides a unique identification. When beginning a transaction, the status of the certificate is checked by using one of two methods:
- The **Certification Revocation List** (**CRL**)
- The **Online Certificate Status Protocol** (**OCSP**)

The CRL is a list of certificates that in some way have been deemed invalid. Although the CRL is effective, most online services have moved to the newer OCSP to check the validity of the certificate.

This process is as shown in the graphic:
![[Pasted image 20240104113056.png|670]]
*Standard OSCP Process.*

Let’s take a look at how this works. When a client goes to a web server to initiate a transaction, the following process occurs:
1. The web server sends the client the certificate.
2. The client then goes to the OCSP server to check the validity of the certificate.

While this is a valid process, another way to achieve this is by using certificate stapling. Let’s see why this improves efficiency.

#### Stapling the Certificate
In the standard approach to determine the validity of a certificate, the burden rests on the client, who must check with the OCSP server to confirm the validity of the certificate.

Stapling the certificate reverses this burden, so the web server must validate the certificate, as shown in the graphic:
![[Pasted image 20240104113152.png|670]]
*OSCP Process using Stapling.*

With certificate stapling, when a client begins a web server transaction, the following process occurs:
1. The web server goes to the OCSP server to check the validity of the certificate
2. The web server then sends the validated certificate to the client.

Because attacks can occur when using a flawed digital certificate, the team may be tasked to assess that any SSL/TLS are properly signed and are secure.

> [!warning] What is Certificate Pinning?
> An older security mechanism mentioned in the objectives is **certificate pinning**. Certificate pinning associates a host with an X.509 certificate (or a public key) and the uses the that association to make a trust decision. This means that if the certificate changes, the remote system will no longer be recognized and the client shouldn't be able to visit it. Pinning can cause issues, particularly if an organization uses data loss prevention (DLP) proxies that intercept traffic. Pinning can work with this if the interception proxy is also added to the pinning list, called a *pinset*.

> [!important] Certificate Pinning vs. Stapling
> Stapling is just the server providing the client with the response showing that the server's certificate is valid. Pinning is when the client has a certificate built in, and only considers that exact certificate as valid.


## Topic 3D - Discover Open-Source Intelligence Tools
---
> [!note] Exam Objectives Covered
> *2.1 Given a scenario, perform passive reconnaissance.*
> *5.3 Explain use cases of the following tools during the phases of a penetration test.*

When searching a closed-source or private site, you will need permission, generally in the form of a user ID and password, to enter the site and search for information. In addition, a closed-source site will most likely have limited access and visibility. This is done to keep information secure and protect sensitive data. In contrast, open-source sites allow anyone, regardless of affiliation or authorization, to freely search and gather information without interfering with any laws or regulations.

In this section, we’ll drill down on some popular OSINT tools such as Metagoofil and Recon-ng and discover how to sift through metadata and research organizational information. We’ll then finish with a discussion on how the power of Maltego and Shodan can help the team ferret out valuable information on the target.

Let’s start with learning where the sources of OSINT tools are currently available.

### Unearthing OSINT Tools
---
Open-source intelligence tools are used during the reconnaissance phase to gather actionable information from freely and publicly available sources, for a more targeted discovery. Using OSINT is critical to the preliminary phases of a PenTest, as it allows the team to discreetly gather information on the target without signaling any flags.

There are many potential sources of OSINT, and most are connected to the Internet. Some examples include:
- Registration information from Whois databases.
- The target's public website and any related websites.
- Social media profile of the target and any associated individuals.
- Job postings, blogs, and news articles
- Information gathered from querying public DNS servers.
- Mail server records gathered from public DNS servers.
- Information gathered from website SSL/TLS certificates.

In this section, we’ll drill down on some popular OSINT tools, such as Metagoofil. Shodan, Maltego, and Recon-ng.

Let's first learn how to unearth metadata from publicly accessible resources.

### Searching Metadata
---
When searching for actionable intel, the team will find metadata entries that can expose sensitive information. Metadata is information stored or recorded as a property of an object, state of a system, or transaction. Metadata includes information such as the author, company, title, and subject. However, there is additional metadata, that has minimal relevance, such as time spent editing the document and word count.

Two tools that aid in the discovery of metadata are Metagoofil and Fingerprinting Organizations with Collected Archives (FOCA). Let's start with Metagoofil.

#### Using Metagoofil
Metagoofil is a Linux-based tool that can search for metadata from public documents located on the target website(s). It uses Python scripting to locate metadata within different document types such as `df`, `doc`, `xls`, `ppt`, `odp`, `ods`, `docx`, `xlsx`, and `pptx`. Metadata entries includes information such as the author, company, title, and subject. However, there is additional metadata that has minimal relevance such as time spent editing the document and word count.

> [!warning] Metagoofil is like the app goofile, which can search for a specific file type in a specific domain.
> 

Metagoofil uses various python libraries such as PdfMiner, GoogleSearch, and Hachoir to scrape the metadata, and then displays the information using Hypertext Markup Language (HTML). The output can then be viewed in a standard browser.

You can download a copy of Metagoofil from GitHub. In addition, the tool is built into Kali Linux. When searching, enter commands that control the type of data that is returned. Some examples include:

| **Command**          | **Results**                                      |
|:-------------------- |:------------------------------------------------ |
| **`-d comptia.org`** | Scan for documents on Comptia.org                |
| **`-t pdf`**         | Scan for pdf documents                           |
| **`-l 75`**          | Search for 75 documents                          |
| **`-n 25`**          | Download 25 files                                |
| **`-o comptiapdf`**  | Save the downloads to the *comptiapdf* directory |
*Options when using Metagoofil*

Another valuable tool is FOCA, which can discover metadata from a variety of sources.

#### Fingerprinting with FOCA
FOCA is a Graphical User Interface (GUI) OSINT tool used to discover metadata that may be hidden within documents, typically those downloaded from the web. Over the years, FOCA's functionality has expanded and it can also gather additional information, such as other domains associated with the primary IP address.

Like other OSINT tools, FOCA can scan using search engines such as Google, Bing, and DuckDuckGo to find downloadable files. However, you can also provide local files for FOCA to analyze. In addition, you can customize your search.

FOCA can work with a variety of document types, including Microsoft Office (`.docx`, `.xlsx`, etc.) along with the OpenDocument format (`.odt`, `.ods`, etc.). It can also analyze PDFs and graphical design file types like the XML-based Scalable Vector Graphics (SVG) format.

Some of the useful metadata FOCA can extract includes user and people names, software and OS version information, printer information, plaintext passwords, and more. Note that, unlike theHarvester, Recon-ng, and Maltego, FOCA is a Windows-only tool. In addition, it also requires a running SQL server to store its data in a database.

Next, let’s take a look at ways we can gather organizational data.

### Researching Organizational Information
---
During reconnaissance, the team will discover other sources that can provide actionable intel on an organization. One way to enumerate users is by monitoring responses on a login page. For example, you could enter the following KliSah. If the prompt returned "User does not exist," as shown in the graphic, that would verify that the username was not in the database:
![[Pasted image 20240104113911.png]]
*Username does not exist*

On the other hand, if you enter the username and password and the prompt returned "Password is incorrect," as shown in the graphic, that will verify that the username is in the database:
![[Pasted image 20240104113937.png]]
*Password is not correct*

The responses will also reveal how the server responds to "known good" and "known bad" input.

In addition to collecting and monitoring form data, two OSINT tools that can provide organizational information are theHarvester and Recon-ng.

#### Collecting Data with theHarvester
theHarvester is an intuitive tool that can search a company's visible threat landscape. The tool gathers information on the following:
- Subdomain names
- Employee names
- Email addresses
- PGP key entries
- Open ports and service banners

theHarvester is relatively simple to use and can automate the information gathering tasks by using multiple methods that include:
- Google and Bing to gather information from public data sources.
- Comodo's certificate search engine to obtain certificate information.
- Social media sites like Twitter and LinkedIn.
- Banner grabbing functionality using Shodan.

When using theHarvester, you will enter the target domain and the data source. For example, we see in the screenshot below commands to a search contacts from a domain **( `-d comptia.org`)** using LinkedIn **( `-b LinkedIn`)**:

![[Pasted image 20240104114118.png|600]]
*Using theHarvester*

Once the data is obtained, the PenTesters can use this information in an exploit, such as a Spearphishing attack.
Another example is Recon-ng, which is like theHarvester. However, it is more robust, as it includes dozens of different modules.

#### Gathering with Recon-ng
Recon-ng uses modules to customize the search. When searching, you can run a specific type of query and then set various options that are either required or optional.

Some modules include:
- Whois query to identify points of contact
- PGP key search.
- Social media profile associations.
- File crawler.
- DNS record enumerator

In addition, you can do an email address search in the Have I Been Pwned? database, which will indicate if the account has been associated with a recent breach. Malicious actors harvest credentials and then provide massive password dumps on the dark web that can be obtained for a fee.

Once you enter your query, Recon-ng will present the information, as shown in the screenshot showing a Whois profile of Comptia.org:
![[Pasted image 20240104114202.png]]
*Enumerating Whois data in Recon-ng (Screenshot courtesy of CompTIA.)*

In addition to gathering organizational data, the team might want to view commonalities among data sources. Maltego is an OSINT tool that can gather a wide variety of information on public resources and then provide a visual on the shared features among all sources. Let's take a look.

### Transforming Data with Maltego
---
As opposed to searching with theHarvester and Recon-ng using a CLI, Maltego has a full GUI to help users visualize the gathered information. Maltego features an extensive library of "transforms," which automate the querying of public sources of data. Maltego then compares the data with other sets of information to provide commonalities among the sources.

Some of the data Maltego can enumerate includes:
- Individual's names and physical addresses
- Network address blocks
- Phone numbers and email addresses
- External links
- DNS records and subdomains
- Downloadable files
- Social media profiles

The results of the query are then placed in node graphs, and then links are established between each node. This enables the user to analyze how two or more data points may be connected.

If you run a transform on a domain, Maltego can place that domain at the top of a tree hierarchy with several branching links to other resources under that domain. For example, resources can include subdomains enumerated through DNS. Under these subdomains might be IP addresses and address ranges.

As shown in the screenshot, we see a Maltego graph illustrating the links between different objects in a domain transform hierarchy for Paterva.com:
![[Pasted image 20240104114255.png | 800]]
*A Maltego graph (Screenshot courtesy of Maltego Technologies GmbH.)*

When conducting a people-oriented search, the resources that branch off the domain might include personnel phone numbers, email addresses, and so on. Maltego provides more than just hierarchical layouts; you can also show objects in a circular layout, block layout, organic layout (minimal distance between entities), and more.

Note that Maltego is proprietary software and comes in several editions. Maltego CE is the free edition that requires you to register with a Maltego Community account in order to take advantage of a limited set of available transforms.

During footprinting and reconnaissance, it’s also advantageous to search for public or improperly secured devices that allow remote access through the Internet. Let’s see how this is possible using Shodan next.

### Searching with Shodan
---
The Internet of Things (IoT) has billions of devices that are talking to us and to each other. Shodan is a search engine designed to locate and index IoT devices that are connected to the Internet.

For example, a zoo might set up an IP camera in one of its enclosures for anyone in the world to watch the animals through a browser. Shodan indexes this connection by grabbing service banners sent by a device to a client over a specific port.

Other IoT devices indexed by Shodan can include traffic lights, industrial control systems (ICSs), and other devices that have Internet connectivity and are part of the IoT. Many devices are lax when it comes to security, and some may even allow a user full remote control. For example, someone might purchase an IP camera to use as surveillance at their home or office, and they may fail to change the default username and password from "admin" and "admin123" to something more secure.

Shodan can be useful to the PenTest reconnaissance phase in several ways:
- If the team is planning on conducting a physical test, they can attempt to locate the feed of a security camera outside the target organization’s office. If successful, the team can get a better picture of the premises and its defenses.
- If the target organization employs control systems for Heating Ventilation Air Conditioning (HVAC) or industrial equipment, the team may be able to control these remotely as part of the attack phase.

> [!warning] Although the PenTest+ exam outline only covers Shodan and Censys, other tools are available, such as ZoomEye.org - a search engine that provides somewhat similar capabilities to Shodan and Censys. Other commercial tools like hunter.io search engine can be used to identify email address patterns as well as email addresses for organizations simply based on their domain.

